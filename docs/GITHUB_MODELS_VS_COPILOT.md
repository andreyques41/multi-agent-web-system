# GitHub Models vs GitHub Copilot

## üî¥ IMPORTANTE: Son servicios DIFERENTES

### GitHub Copilot (lo que usas en VS Code)
- **Qu√© es**: Asistente de IA integrado en tu IDE
- **D√≥nde**: VS Code, Visual Studio, JetBrains, etc.
- **Modelos disponibles**: GPT-4, Claude 3.5 Sonnet, y otros
- **C√≥mo funciona**: Autocompletado de c√≥digo, chat, agente de codificaci√≥n
- **Acceso**: A trav√©s de tu suscripci√≥n de GitHub Copilot
- **URL**: No usa API directa, integraci√≥n nativa en el IDE

### GitHub Models (API que usa este proyecto)
- **Qu√© es**: Servicio de API para experimentar con modelos
- **D√≥nde**: API REST en `https://models.inference.ai.azure.com`
- **Modelos disponibles**: 
  - ‚úÖ OpenAI (GPT-4o, GPT-5, GPT-4.1, o1, o3, o4-mini, etc.)
  - ‚úÖ Microsoft Phi-4
  - ‚úÖ Meta Llama 3.3, 3.2, 4
  - ‚úÖ DeepSeek R1, V3
  - ‚úÖ Mistral, Grok, Cohere, AI21 Jamba
  - ‚ùå **Claude/Anthropic NO est√° disponible**
- **C√≥mo funciona**: Llamadas API directas usando token de GitHub
- **Acceso**: Token de GitHub con permiso 'models'
- **Cat√°logo**: https://models.github.ai/catalog/models
- **Inferencia**: https://models.inference.ai.azure.com

## ‚ùì ¬øPor qu√© Claude funciona en Copilot pero NO en GitHub Models?

**GitHub Copilot** tiene acuerdos especiales con Anthropic para ofrecer Claude a sus usuarios pagos. Esto es parte del producto Copilot.

**GitHub Models** es un servicio separado (playground + API) que solo ofrece modelos de OpenAI, Microsoft, Meta, DeepSeek y otros - pero NO incluye Claude.

Ver cat√°logo oficial: https://github.com/marketplace/models/catalog

## üìù Nota sobre nomenclatura de modelos

**IMPORTANTE**: Hay una diferencia entre c√≥mo se muestran los modelos y c√≥mo se usan:

### Cat√°logo API (https://models.github.ai/catalog/models):
- Muestra modelos con prefijo de proveedor: `"openai/gpt-4o"`, `"microsoft/phi-4"`, etc.

### Inferencia API (https://models.inference.ai.azure.com):
- Usa solo el nombre del modelo: `"gpt-4o"`, `"Phi-4"`, etc.
- **NO incluir el prefijo del proveedor**

Ejemplo:
```python
# ‚ùå INCORRECTO (falla con error 400)
model = "openai/gpt-4o"

# ‚úÖ CORRECTO (funciona)
model = "gpt-4o"
```

## ‚úÖ Soluci√≥n para este proyecto

Como este proyecto usa la **GitHub Models Inference API**, solo podemos usar modelos disponibles en ese servicio:

### Modelos recomendados por agente:

| Agente | Modelo | Raz√≥n |
|--------|--------|-------|
| Business Analyst | `gpt-4o` | Mejor modelo probado y estable |
| Project Manager | `gpt-4o` | Planificaci√≥n y documentaci√≥n |
| Backend Developer | `gpt-4o` | Excelente para c√≥digo |
| Frontend Developer | `gpt-4o` | UI/UX y c√≥digo |
| DevOps Engineer | `gpt-4o` | Infrastructure as Code |
| QA Engineer | `gpt-4o` | Tests y validaci√≥n |

**Nota**: GPT-4o est√° verificado y funciona perfectamente. Los modelos m√°s nuevos (GPT-5, GPT-4.1, o3) podr√≠an funcionar pero no est√°n testeados en este proyecto todav√≠a.

### Modelos disponibles en GitHub Models:

```python
MODELOS_VERIFICADOS = {
    "gpt-4o": "‚úÖ PROBADO - Funciona perfectamente",
    "gpt-4o-mini": "‚úÖ Disponible - Versi√≥n m√°s peque√±a",
}

MODELOS_DISPONIBLES_NO_PROBADOS = {
    # OpenAI GPT-5 Series
    "gpt-5": "√öltima generaci√≥n - NO probado",
    "gpt-5-chat": "Optimizado para chat - NO probado",
    "gpt-5-mini": "Versi√≥n peque√±a - NO probado",
    "gpt-5-nano": "Versi√≥n ultra peque√±a - NO probado",
    
    # OpenAI GPT-4.1 Series
    "gpt-4.1": "Nueva versi√≥n mejorada - NO probado",
    "gpt-4.1-mini": "Versi√≥n peque√±a - NO probado",
    "gpt-4.1-nano": "Versi√≥n ultra peque√±a - NO probado",
    
    # OpenAI o Series (Reasoning)
    "o1": "Razonamiento avanzado - NO probado",
    "o1-mini": "Versi√≥n peque√±a - NO probado",
    "o3": "√öltima generaci√≥n - NO probado",
    "o4-mini": "Versi√≥n peque√±a - NO probado",
    
    # Microsoft Phi
    "Phi-4": "Modelo peque√±o de Microsoft - NO probado",
    "Phi-4-reasoning": "Con razonamiento - NO probado",
}
```

### Alternativas si necesitas Claude:

1. **Usar Anthropic directamente**:
   - Crea una API key en https://console.anthropic.com
   - Configura `ANTHROPIC_API_KEY` en tu `.env`
   - Cambia `LLM_PROVIDER=anthropic`
   - ‚ö†Ô∏è Esto tiene costo ($)

2. **Usar OpenAI directamente**:
   - Crea una API key en https://platform.openai.com
   - Configura `OPENAI_API_KEY` en tu `.env`
   - Cambia `LLM_PROVIDER=openai`
   - ‚ö†Ô∏è Esto tiene costo ($)

3. **Mantener GitHub Models** (RECOMENDADO):
   - Gratis con tu suscripci√≥n de Copilot
   - Usa GPT-4o (verificado y funcionando)
   - Ya est√° configurado correctamente

## üß™ Probar los modelos

```bash
# Ver qu√© modelos est√°n disponibles
c:\Users\ANDY\repos\multi-agent-web-dev\venv\Scripts\python.exe main.py check-config

# Probar un modelo espec√≠fico (VERIFICADO ‚úÖ)
c:\Users\ANDY\repos\multi-agent-web-dev\venv\Scripts\python.exe main.py test-llm --model gpt-4o

# Probar otros modelos disponibles (no verificados)
c:\Users\ANDY\repos\multi-agent-web-dev\venv\Scripts\python.exe main.py test-llm --model gpt-5
c:\Users\ANDY\repos\multi-agent-web-dev\venv\Scripts\python.exe main.py test-llm --model gpt-4.1
c:\Users\ANDY\repos\multi-agent-web-dev\venv\Scripts\python.exe main.py test-llm --model o3

# Intentar Claude (fallar√° - NO disponible en GitHub Models)
c:\Users\ANDY\repos\multi-agent-web-dev\venv\Scripts\python.exe main.py test-llm --model claude-4.5-sonnet
# ‚ùå Error: unknown_model (porque no est√° en GitHub Models API)
```

## üìö Referencias

- GitHub Models Catalog: https://github.com/marketplace/models/catalog
- GitHub Models API Catalog: https://models.github.ai/catalog/models
- GitHub Models Inference Endpoint: https://models.inference.ai.azure.com
- GitHub Models Docs: https://docs.github.com/en/github-models
- GitHub Models API: https://docs.github.com/en/rest/models
- GitHub Copilot: https://docs.github.com/en/copilot

## üí° Conclusi√≥n

Cuando dices "uso Claude con GitHub Copilot", es **correcto** - Copilot Chat en VS Code te da acceso a Claude.

Pero este proyecto usa la **GitHub Models API** (no Copilot), y esa API no incluye Claude.

La soluci√≥n es usar GPT-4o, que es un excelente modelo, est√° disponible gratis en GitHub Models, y est√° **verificado funcionando** en este proyecto.

## üéØ Estado actual del proyecto

‚úÖ **CONFIGURACI√ìN COMPLETADA Y VERIFICADA**

- Provider: GitHub Models
- Modelo principal: GPT-4o
- Token: Configurado y funcionando
- Test: ‚úÖ `python main.py test-llm --model gpt-4o` exitoso
- Listo para crear el primer proyecto

```bash
# Crear tu primer proyecto de prueba
c:\Users\ANDY\repos\multi-agent-web-dev\venv\Scripts\python.exe main.py create \
  --project landing \
  --name "Mi Landing Page" \
  --description "Landing page de prueba para una PyME" \
  --verbose
```

