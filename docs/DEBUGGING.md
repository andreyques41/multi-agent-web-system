# üêõ Gu√≠a de Debugging

Esta gu√≠a te muestra c√≥mo hacer debugging del sistema multi-agente.

## üß™ Comandos de Debugging

### 1. **Probar Conexi√≥n con el LLM**

Antes de crear un proyecto, prueba que tu configuraci√≥n funciona:

```bash
# Probar con el modelo por defecto
python main.py test-llm

# Probar con un modelo espec√≠fico
python main.py test-llm --model claude-4.5-sonnet
python main.py test-llm --model gpt-5.1-codex

# Probar con un prompt personalizado
python main.py test-llm --prompt "Dame un ejemplo de c√≥digo Python"
```

**Qu√© hace:**
- Conecta con el LLM configurado
- Env√≠a un prompt simple
- Muestra la respuesta
- Si falla, te da pistas de qu√© est√° mal

**Ejemplo de salida exitosa:**
```
‚úÖ LLM funcionando correctamente!

‚ï≠‚îÄ Respuesta del LLM ‚îÄ‚ïÆ
‚îÇ ¬°Hola! S√≠, funciono ‚îÇ
‚îÇ correctamente.      ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

---

### 2. **Verificar Configuraci√≥n**

```bash
python main.py check-config
```

**Qu√© muestra:**
- Provider actual (GitHub/OpenAI/Anthropic)
- Modelo por defecto
- Modelos asignados a cada agente
- Todos los modelos disponibles
- Si hay alg√∫n error de configuraci√≥n

---

### 3. **Modo Verbose**

Ver logs detallados durante la creaci√≥n del proyecto:

```bash
python main.py create --project landing --name "Test" --verbose
```

**Qu√© muestra:**
- Qu√© agente est√° trabajando
- Qu√© tarea est√° ejecutando
- Progreso de cada paso
- Logs de CrewAI

---

### 4. **Modo Debug**

Ver TODO incluyendo llamadas al LLM:

```bash
python main.py create --project landing --name "Test" --debug
```

**Qu√© muestra:**
- Todo lo del modo verbose
- Prompts enviados al LLM
- Respuestas del LLM
- Errores detallados
- Stack traces completos

---

### 5. **Guardar Logs en Archivo**

```bash
# Crear directorio de logs
mkdir logs

# Ejecutar con logs
python main.py create --project landing --name "Test" --debug --log-file logs/proyecto.log
```

**Ventajas:**
- Puedes revisar los logs despu√©s
- √ötil para reportar errores
- No pierdas informaci√≥n si falla

---

## üîç Estrategia de Debugging

### Paso 1: Verificar Configuraci√≥n B√°sica

```bash
python main.py check-config
```

**Verifica:**
- ‚úÖ Aparece tu provider (GITHUB)
- ‚úÖ Aparecen los modelos
- ‚úÖ No hay errores rojos

---

### Paso 2: Probar Conexi√≥n con LLM

```bash
# Probar GPT
python main.py test-llm --model gpt-5.1

# Probar Claude
python main.py test-llm --model claude-4.5-sonnet
```

**Si falla:**
- ‚ùå `authentication error` ‚Üí Token inv√°lido o sin permisos
- ‚ùå `model not found` ‚Üí El modelo no existe en GitHub Models
- ‚ùå `rate limit` ‚Üí Demasiadas peticiones

---

### Paso 3: Crear Proyecto con Logs

```bash
python main.py create --project landing --name "Test Debug" --verbose --log-file logs/test.log
```

**Observa:**
- ¬øEn qu√© agente falla?
- ¬øQu√© error muestra?
- Revisa `logs/test.log` para detalles

---

## üö® Errores Comunes y Soluciones

### Error: `AnthropicException - invalid x-api-key`

**Causa:** El sistema est√° intentando usar Anthropic directamente en lugar de GitHub Models.

**Soluci√≥n:**
```bash
# Verifica que est√©s usando GitHub
echo $env:LLM_PROVIDER  # Windows
# Debe decir "github"

# Si no, edita .env
LLM_PROVIDER=github
```

---

### Error: `GITHUB_TOKEN not found`

**Causa:** No configuraste el token de GitHub.

**Soluci√≥n:**
```bash
# Genera token en https://github.com/settings/tokens
# Edita .env y agrega:
GITHUB_TOKEN=ghp_tu_token_aqui
```

---

### Error: `Model not found`

**Causa:** El modelo que especificaste no existe.

**Soluci√≥n:**
```bash
# Ver modelos disponibles
python main.py check-config

# Usa uno de los listados, ej:
python main.py test-llm --model gpt-5.1
```

---

### Error: `Rate limit exceeded`

**Causa:** Demasiadas peticiones al LLM.

**Soluci√≥n:**
- Espera 1 minuto
- GitHub Models tiene l√≠mites por minuto
- Considera usar modelos m√°s peque√±os (gpt-4o en lugar de gpt-5.1)

---

## üìä Interpretando los Logs

### Modo Verbose

```
2025-11-14 10:30:15 - crew - INFO - Starting Task: business_analyst_task
2025-11-14 10:30:20 - agent - INFO - Business Analyst is analyzing requirements
2025-11-14 10:30:45 - crew - INFO - Task completed successfully
```

**Indica:**
- Qu√© tarea est√° ejecut√°ndose
- Qu√© agente est√° trabajando
- Si complet√≥ exitosamente

---

### Modo Debug

```
2025-11-14 10:30:15 - llm - DEBUG - Sending prompt to claude-4.5-sonnet
2025-11-14 10:30:16 - llm - DEBUG - Prompt: Analyze these requirements...
2025-11-14 10:30:45 - llm - DEBUG - Response received: Based on the requirements...
```

**Indica:**
- Qu√© se est√° enviando al LLM
- Qu√© responde el LLM
- √ötil para ver si el prompt es correcto

---

## üéØ Casos de Uso

### Caso 1: Claude no funciona

```bash
# 1. Prueba si Claude funciona
python main.py test-llm --model claude-4.5-sonnet

# 2. Si falla, usa GPT temporalmente
# Edita .env:
BUSINESS_ANALYST_MODEL=gpt-5.1
PROJECT_MANAGER_MODEL=gpt-5.1

# 3. Vuelve a probar
python main.py create --project landing --name "Test" --verbose
```

---

### Caso 2: Proyecto falla a mitad

```bash
# 1. Ejecuta con logs
python main.py create --project landing --name "Test" --debug --log-file logs/debug.log

# 2. Cuando falle, revisa el log
notepad logs/debug.log

# 3. Busca la √∫ltima l√≠nea antes del error
# Identifica qu√© agente fall√≥
# Reporta el error con el log
```

---

### Caso 3: Quiero ver qu√© est√° pensando el LLM

```bash
# Ejecuta en modo debug
python main.py create --project landing --name "Test" --debug

# Ver√°s:
# - El prompt completo que se env√≠a
# - La respuesta completa del LLM
# - √ötil para entender decisiones del agente
```

---

## üìù Reportar Errores

Si encuentras un error, incluye:

1. **Comando ejecutado:**
   ```bash
   python main.py create --project landing --name "Test"
   ```

2. **Configuraci√≥n:**
   ```bash
   python main.py check-config
   ```
   (Copia la salida)

3. **Error exacto:**
   ```
   Error durante la creaci√≥n del proyecto:
   litellm.AuthenticationError: ...
   ```

4. **Logs (si los tienes):**
   ```bash
   # Adjunta el archivo logs/debug.log
   ```

5. **Entorno:**
   - OS: Windows/Mac/Linux
   - Python: 3.13.7
   - CrewAI: 1.4.1

---

## üîó Recursos Adicionales

- [Configuraci√≥n de GitHub Models](SETUP_GITHUB_MODELS.md)
- [Estrategia de Modelos](MODEL_STRATEGY.md)
- [Estructura del Proyecto](STRUCTURE.md)
